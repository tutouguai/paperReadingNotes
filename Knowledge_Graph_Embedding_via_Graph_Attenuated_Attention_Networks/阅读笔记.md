# 通过图形衰减的注意力网络进行知识图谱嵌入

## 摘要

图卷积神经网络在知识图的<b>关系路径</b>上分配相同的权重，忽略了相邻节点中丰富的信息，导致了三重特征的不完全挖掘。为此，我们提出了一种新的表示方法——衰减注意网络（GAAT），它集成了一种衰减注意机制，在不同的关系路径中分配不同的权重，并从邻域中获取信息。因此，实体和关系可以在任何邻居中学习。

## 1. 背景介绍和论文主要工作

模型引入了衰减注意机制，同时考虑了n-跳邻居(<b>e实体离给定实体越近，获得的注意力的权重就越高</b>)模型分别训练关系嵌入和实体嵌入。

### 1.1主要工作

- 引入了图注意力网络
- 针对图卷积神经网络的局限性，提出了衰减注意力机制，并提出了一种基于图衰减注意力网络的实体和关系的嵌入方法
- 利用n跳邻居节点的信息来拓展实体和关系的表示
- 使用图注意力衰减网络作为编码器，使用胶囊网络嵌入作为解码器(CapsE:模型支持在更深层次上探索三重特征)

## 2.相关工作介绍

### 2.1张量分解

​		张量分解的基本思想是用多个低维矩阵或张量(二维矩阵)替代原始关系矩阵，从而用少量参数替换稀疏的大量原始数据。(tucker论文-未读)

​		1. RESCAL通过张量因子分解，考虑了二元关系数据的固有结构。

​		2. 神经张量网络(ntn)模型将关系表示为矩阵，以表征潜在特征的相关性。实体与关系之间的双线性匹配用于判断建立关系的可能性。

### 2.2 知识嵌入模型

#### 	2.2.1 平移模型

​	平移模型是基于能量函数的，正确三元组的能量较低，损坏三元组的能量较高。已生成的三元组是否为正确三元组的判断局域能量函数的计算。

 1. TransE 是一个参数较少的简单模型，但在处理一对多和多对一关系时存在一定问题。

 2. 为了解决TransE的问题，提出了超平面上的平移嵌入(TransH)和关系空间中的平移嵌入(TransR),TransH和TransR实验冉关系空间中的替代表示法计算统一试题的分数，有效避免了收敛问题。

    #### 2.2.2 神经网络模型

    ​	知识表示是指如何通过神经网络模型表达实体和关系，从而通过符号计算实体和关系。更注重三元组潜在语义信息。

     1. 神经张量模型(NTN)

     2. 卷积知识库嵌入(ConvKB)

        使用文本关系的内部结构作为卷积层的输入

     3. 卷积网络嵌入(ConvE)

        使用神经网络对三元组进行评分

     4. 关系图卷积网络(R-GCN)

        使用图卷积获取嵌入，使用DistMult获取嵌入的分数

     5. 图卷积网络(GCN)

     6. 胶囊网络嵌入(CapsE)

        将每个三元组表示为3列矩阵,并将其输入胶囊神经网络中。

### 2.3 全息嵌入模型

​	前两种模型的计算量大，为了解决这一限制，提出了全息嵌入模型。通过应用实体嵌入的循环关联性。

### 2.4 路径学习

#### 	2.4.1 RL

​		基于多跳知识嵌入的强化学习用于基于知识图的查询应答

#### 	2.4.2 关系路径嵌入(RPE)

​		关系路径嵌入将多跳关系路径添加到转换模型中，同时将每个实体嵌入到两种类型的潜在空间中。

#### 	2.4.3 PARL

​		基于路径的实现感知表示学习模型(PARL),对关系预测任务进行路径去噪和路径表示学习。

#### 	2.4.4 DPTransE

​		基于辨别路径的嵌入模型，从联合学习的潜在特征和图特征构建交互，并使用图形特征作为提供精确特征和辨别行嵌入的关键先决条件。

#### 	2.4.5 Meta_KGR

​		基于元的多跳知识图推理，采用元学习，从高频关系中学习有效的元参数，可以适应寥寥无几的关系

### 2.5 注意力机制

​	注意力机制与神经网络模型的结合也得到了广泛的关注，其目的是提高模型的鲁棒性。

#### 	2.5.1 注意力图卷积网络(AGCN)

​		由注意机制层和图卷积神经网络(GCN)组成，用于在大SAP(<b>???</b>)图像数据中执行超像素分割。

#### 	2.5.2 图注意力模型(GAM)

​		关注图形中较小但信息丰富的部分，避免图形其余部分的噪声。

### 2.6 其它

#### 	2.6.1 KPRN

​		知识感知路径递归网络（KPRN）通过组合实体和关系的语义生成路径表示，并允许对路径进行有效推理，以推断用户项交互的基本原理，以进行推荐。

	#### 	2.6.2KGAT

​		知识图注意网络(KGAT)递归的传播来自节点邻居的嵌入一细化节点嵌入，并使用注意力机制来区分邻居的重要性以进行推荐。

### 2.7 总结

​	但是现有的模型只考虑关系嵌入作为实体嵌入的辅助特征，并没有深入地考虑如何嵌入关系。此外，当两个实体之间存在间接连接（不是一跳关系）时，以前的研究将相同的权重分配给每个跳的关系，导致部分相邻三元组的信息丢失。目前，文献中还没有集成神经网络模型和平移模型的模型，利用了这两种模型的优点。在这里，我们提出了一个组合模型，<b>以进一步提高任务的知识图完成方面的预测精度和计算成本(提高计算成本????)</b>。



## 3.方法

 节点的注意值可以形式化为 ${\large e_{ij}=f_{a}(W_{e_{i},W_{e_{j}}})}$ 

提出了一个参数线性变换矩阵，将输入特征映射到高维输出特征空间。



​	

